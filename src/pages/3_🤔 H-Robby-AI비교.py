import streamlit as st
import os
import urllib.parse
import openai
from langchain_community.chat_models import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
# from transformers import pipeline, GPT2Config, GPT2LMHeadModel, GPT2Tokenizer
from modules.chatbot2 import Chatbot2
from langchain_community.embeddings import OpenAIEmbeddings # OpenAIì˜ ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‹¨ì–´ ì„ë² ë”©ì„ ìƒì„±
from langchain_chroma import Chroma # ë²¡í„° ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ì¿¼ë¦¬í•  ìˆ˜ ìˆëŠ” ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µ
# import llm_blender
# from transformers import AutoTokenizer, AutoModelForCausalLM
from modules.history import ChatHistory
from modules.chromaManager import ChromaManager

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

# OpenAI API í‚¤ ë¡œë“œ
openai.api_key = os.getenv('OPENAI_API_KEY')

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(layout="wide", page_icon="ğŸ¤–", page_title="AI ëª¨ë¸ ë¹„êµ")

history = ChatHistory()

# ì§ˆì˜ ì…ë ¥ UI
st.markdown(
    """
    <head>
        <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans+KR:wght@400;600&display=swap" rel="stylesheet">
    </head>
    <h1 style='text-align: center; font-family: "IBM Plex Sans KR", sans-serif;'> H-Robbyê°€ AI ëª¨ë¸ì„ ë¹„êµí•´ë“œë ¤ìš” ğŸ¤”</h1>
    """,
    unsafe_allow_html=True,
)

st.write("ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  ê° ëª¨ë¸ì˜ ì‘ë‹µ ë° ë¹„ìš©ì„ ë¹„êµí•´ë³´ì„¸ìš”.")
user_query = st.text_input("ì§ˆë¬¸ ì…ë ¥", placeholder="ì˜ˆ: í˜„ëŒ€í“¨ì²˜ë„·ì€ ì–´ë””ì— ìœ„ì¹˜í•´ìˆë‚˜ìš”?")

# Chatbot2 ê°ì²´ ì´ˆê¸°í™”
# retriever = None  # Retrieverë¥¼ í•„ìš”ì— ë”°ë¼ ì´ˆê¸°í™”
vector_store = Chroma(persist_directory="./chroma_db", embedding_function=OpenAIEmbeddings())
retriever = vector_store.as_retriever(search_kwargs={"k": 10})

persist_directory = "./chroma_db"  # ë¡œì»¬ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì§€ì •
manager = ChromaManager(persist_directory=persist_directory)    # client, retriever ì´ˆê¸°í™” ë° db ë¡œë“œ
retriever = manager.get_retriever()

openai_chatbot = Chatbot2("OpenAI", "gpt-4", 0.7, retriever)
gemini_chatbot = Chatbot2("Gemini", "gemini-pro", 0.7, retriever)
huggingface_chatbot = Chatbot2("HuggingFace", "gpt2", 0.7, retriever)

# ëª¨ë¸ ì‘ë‹µ ì»¨í…Œì´ë„ˆ
if user_query:
    with st.spinner("ëª¨ë¸ ì‘ë‹µì„ ìƒì„± ì¤‘..."):
        # OpenAI ì‘ë‹µ
        openai_response = openai_chatbot.chat(user_query)
        openai_cost = len(user_query) * 0.02  # ì˜ˆì‹œ ë¹„ìš© ê³„ì‚°

        # Gemini ì‘ë‹µ
        gemini_response = gemini_chatbot.chat(user_query)
        gemini_cost = len(user_query) * 0.015  # ì˜ˆì‹œ ë¹„ìš© ê³„ì‚°

        # HuggingFace ì‘ë‹µ
        huggingface_response = huggingface_chatbot.chat(user_query)
        # huggingface_cost = len(user_query) * 0.01  # ì˜ˆì‹œ ë¹„ìš© ê³„ì‚°


        # ê²°ê³¼ í‘œì‹œ
        st.markdown("## ëª¨ë¸ ì‘ë‹µ ë¹„êµ")
        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("### OpenAI")
            st.text_area("OpenAIì‘ë‹µ", value=openai_response["answer"], height=350)
            # st.write(f"ë¹„ìš©: ${333:.4f}")
            st.write(f"ë¹„ìš©: ${openai_cost:.4f}")
            # Display metadata in expander
            # ì¤‘ë³µ ì œê±°
            retrieved_documents = openai_response["documents"]
            unique_documents = list({(doc.metadata.get("source"), doc.metadata.get("page")): doc for doc in retrieved_documents}.values())
            with st.expander("ê´€ë ¨ ë§¤ë‰´ì–¼ ë§í¬ ğŸ”—"):
                # retrieve_contextì—ì„œ ì‚¬ìš©ëœ context ë°ì´í„°ë¥¼ ì €ì¥
                if unique_documents:
                    st.subheader("ê´€ë ¨ ë§¤ë‰´ì–¼")
                    for doc in unique_documents:
                        metadata = doc.metadata
                        source = metadata.get("source", "Unknown Source")
                        page = metadata.get("page", "Unknown Page")

                        # í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ë¡œ ë³€í™˜
                        format_source = f"file://{urllib.parse.quote(source)}"  # ê²½ë¡œ ë³€í™˜

                        st.markdown(f"- [Source: {source} (Page {page})]({format_source})", unsafe_allow_html=True)
                else:
                    st.write("ë©”íƒ€ë°ì´í„° ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

        with col2:
            st.markdown("### Gemini")
            st.text_area("Geminiì‘ë‹µ", value=gemini_response["answer"], height=350)
            # st.write(f"ë¹„ìš©: ${222:.4f}")
            st.write(f"ë¹„ìš©: ${gemini_cost:.4f}")
            # Display metadata in expander
            # ì¤‘ë³µ ì œê±°
            retrieved_documents = gemini_response["documents"]
            unique_documents = list({(doc.metadata.get("source"), doc.metadata.get("page")): doc for doc in retrieved_documents}.values())
            with st.expander("ê´€ë ¨ ë§¤ë‰´ì–¼ ë§í¬ ğŸ”—"):
                # retrieve_contextì—ì„œ ì‚¬ìš©ëœ context ë°ì´í„°ë¥¼ ì €ì¥
                if unique_documents:
                    st.subheader("ê´€ë ¨ ë§¤ë‰´ì–¼")
                    for doc in unique_documents:
                        metadata = doc.metadata
                        source = metadata.get("source", "Unknown Source")
                        page = metadata.get("page", "Unknown Page")

                        # í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ë¡œ ë³€í™˜
                        format_source = f"file://{urllib.parse.quote(source)}"  # ê²½ë¡œ ë³€í™˜

                        st.markdown(f"- [Source: {source} (Page {page})]({format_source})", unsafe_allow_html=True)
                else:
                    st.write("ë©”íƒ€ë°ì´í„° ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

        with col3:
            st.markdown("### HuggingFace")
            st.text_area("HuggingFaceì‘ë‹µ", value=huggingface_response, height=350)
            st.write(f"ë¹„ìš©: free")
            # st.write(f"ë¹„ìš©: ${huggingface_cost:.4f}")



# ì•™ìƒë¸” ì„¤ì • ê°€ì´ë“œ
# st.sidebar.markdown(
#     """
#     ### ğŸ“Œ ê°€ì´ë“œ
#     - ê° ëª¨ë¸ì˜ ì‘ë‹µ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•´ ì•™ìƒë¸” ì‘ë‹µ ê²°ê³¼ë¥¼ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
#     - ê°€ì¤‘ì¹˜ í•©ì€ **1.0**ì´ ë˜ì–´ì•¼ ê°€ì¥ ì •í™•í•œ ê²°ê³¼ë¥¼ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
#     """
# )
